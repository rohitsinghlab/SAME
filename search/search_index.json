{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SAME","text":"<p>Spatial Alignment of Multimodal Expression</p> <p></p> <p>SAME is a computational framework for aligning and integrating spatial omics data across serial tissue sections and modalities (e.g., proteins, transcripts, metabolites). SAME introduces space-tearing transforms, enabling controlled, localized topological disruptions during cross-sectional alignment.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> <p>Topology-flexible transforms: Unlike rigid registration methods, SAME allows controlled space-tearing events where spatial relationships can break (e.g., when a cell is missing in one section)</p> </li> <li> <p>Mixed Integer Programming: Uses Gurobi MIP solver for optimal cell matching with spatial constraints via Delaunay triangulation. Leverages Gurobi MIP solver's lazy constraint feature to add constraints on-demand instead of upfront.</p> </li> <li> <p>Metacell support: Offers graph simplification for handling large datasets and for large space tears(~100k+ cells) efficiently</p> </li> <li> <p>Lazy constraints: Memory-efficient constraint generation instead of enumerating all O(n\u00d7k\u00b3) constraints upfront.</p> </li> <li> <p>Sliding window: Offers processing arbitrarily large spatial regions in overlapping windows with automatic merging when regions are too large to be processed in a single step.</p> </li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from src import run_same, init_optim_params\n\n# Basic matching\nmatches, var_out = run_same(\n    ref_df=reference_data,\n    aligned_df=moving_data,\n    commonCT=['CellTypeA', 'CellTypeB', 'CellTypeC'],\n    outprefix='results/'\n)\n\nprint(f\"Found {len(matches)} matches\")\n</code></pre>"},{"location":"#when-to-use-same","title":"When to Use SAME","text":"<p>SAME is designed for spatial omics integration tasks where:</p> <ol> <li>Serial sections: Aligning adjacent tissue sections with potentially different cells</li> <li>Multi-modal data: Integrating different spatial technologies (e.g., ISS + IMC)</li> <li>Missing cells: Handling cases where cells appear/disappear between sections</li> <li>Tissue deformation: Accounting for non-rigid tissue changes</li> </ol>"},{"location":"#citation","title":"Citation","text":"<p>If you use SAME in your research, please cite:</p> <p>Aditya Pratapa, Siavash Mansouri, Nadezhda Nikulina, Bruno Matuck, Marc A. Schneider, Kevin Matthew Byrd, Rajkumar Savai, Purushothama Rao Tata, and Rohit Singh. \"SAME: Topology-flexible transforms enable robust integration of multimodal spatial omics.\" bioRxiv (2025): 2025-07. https://doi.org/10.1101/2025.07.12.664419</p>"},{"location":"#contents","title":"Contents","text":"<ul> <li>Installation - How to install SAME</li> <li>Quick Start - Get started in 5 minutes</li> <li>Algorithm Overview - How SAME works</li> <li>API Reference - Function documentation</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python &gt;= 3.9</li> <li>Gurobi optimizer (requires license - free for academics)</li> </ul>"},{"location":"installation/#basic-installation","title":"Basic Installation","text":"<p>Clone the repository and install dependencies:</p> <pre><code>git clone https://github.com/rohitsinghlab/SAME.git\ncd SAME\npip install -e .\n</code></pre> <p>Or install dependencies directly:</p> <pre><code>pip install numpy pandas scipy gurobipy tqdm networkx scikit-learn alphashape shapely\n</code></pre>"},{"location":"installation/#gurobi-license-setup","title":"Gurobi License Setup","text":"<p>SAME requires Gurobi for optimization. Academic users can obtain a free license.</p>"},{"location":"installation/#option-1-web-license-recommended","title":"Option 1: Web License (Recommended)","text":"<ol> <li>Create an account at gurobi.com</li> <li>Request an academic license</li> <li>Get your Web License Service (WLS) credentials</li> <li>Create <code>src/.gurobienv</code> file:</li> </ol> <pre><code>WLSACCESSID=your_access_id\nWLSSECRET=your_secret\nLICENSEID=your_license_id\n</code></pre>"},{"location":"installation/#option-2-environment-variables","title":"Option 2: Environment Variables","text":"<p>Alternatively, set environment variables:</p> <pre><code>export GUROBI_WLSACCESSID=your_access_id\nexport GUROBI_WLSSECRET=your_secret\nexport GUROBI_LICENSEID=your_license_id\n</code></pre>"},{"location":"installation/#option-3-local-license","title":"Option 3: Local License","text":"<p>For local or cluster installations, follow Gurobi's documentation to install and activate a local license.</p>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>For alpha shape filtering (recommended for better boundary detection):</p> <pre><code>pip install alphashape shapely\n</code></pre> <p>For Jupyter notebook support:</p> <pre><code>pip install jupyter ipywidgets\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<pre><code>from src import run_same, init_optim_params\n\n# Check version\nimport src\nprint(f\"SAME version: {src.__version__}\")\n\n# Verify Gurobi\nimport gurobipy as gp\nenv = gp.Env()\nprint(\"Gurobi initialized successfully\")\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#gurobi-license-issues","title":"Gurobi License Issues","text":"<p>If you see \"No Gurobi license found\":</p> <ol> <li>Verify your <code>.gurobienv</code> file exists in <code>src/</code></li> <li>Check credentials are correct</li> <li>Ensure you have network access (for WLS licenses)</li> <li>Try setting environment variables directly</li> </ol>"},{"location":"installation/#memory-issues","title":"Memory Issues","text":"<p>For large datasets (&gt;10,000 cells), use metacells and lazy constraints:</p> <pre><code>from src import greedy_triangle_collapse, init_optim_params\n\n# Create metacells to reduce problem size\nmc_aligned, _ = greedy_triangle_collapse(aligned_df, max_metacell_size=3)\n\n# Use lazy constraints for memory efficiency\noptim = init_optim_params(lazy_constraints=True)\n</code></pre>"},{"location":"installation/#import-errors","title":"Import Errors","text":"<p>If imports fail, ensure you're in the SAME directory or have it in your Python path:</p> <pre><code>import sys\nsys.path.insert(0, '/path/to/SAME')\n</code></pre>"},{"location":"quickstart/","title":"Quick Start","text":"<p>This guide will get you running SAME in under 5 minutes.</p>"},{"location":"quickstart/#input-data-format","title":"Input Data Format","text":"<p>SAME requires two DataFrames with the following columns:</p> Column Required Description <code>X</code>, <code>Y</code> Yes Spatial coordinates <code>cell_type</code> Yes Cell type annotation <code>Cell_Num_Old</code> Yes Unique cell identifier Cell type columns Yes Probability or one-hot columns (e.g., <code>TypeA</code>, <code>TypeB</code>) <p>Example data structure:</p> <pre><code>import pandas as pd\n\n# Reference data (fixed)\nref_df = pd.DataFrame({\n    'Cell_Num_Old': [0, 1, 2, 3],\n    'X': [100, 150, 200, 250],\n    'Y': [100, 120, 100, 130],\n    'cell_type': ['TypeA', 'TypeB', 'TypeA', 'TypeB'],\n    'TypeA': [0.9, 0.1, 0.85, 0.15],  # Probability columns\n    'TypeB': [0.1, 0.9, 0.15, 0.85],\n})\n\n# Aligned/moving data (to be matched)\naligned_df = pd.DataFrame({\n    'Cell_Num_Old': [0, 1, 2, 3, 4],\n    'X': [105, 155, 205, 260, 180],\n    'Y': [95, 125, 105, 125, 110],\n    'cell_type': ['TypeA', 'TypeB', 'TypeA', 'TypeB', 'TypeA'],\n    'TypeA': [0.88, 0.12, 0.9, 0.2, 0.82],\n    'TypeB': [0.12, 0.88, 0.1, 0.8, 0.18],\n})\n</code></pre>"},{"location":"quickstart/#basic-usage","title":"Basic Usage","text":""},{"location":"quickstart/#simple-matching","title":"Simple Matching","text":"<pre><code>from src import run_same\n\n# Run SAME optimization\nmatches, var_out = run_same(\n    ref_df=ref_df,\n    aligned_df=aligned_df,\n    commonCT=['TypeA', 'TypeB'],  # Cell type columns\n    outprefix='results/'\n)\n\n# View results\nprint(f\"Found {len(matches)} matches\")\nprint(matches[['aligned_idx', 'ref_idx', 'X', 'Y', 'ref_X', 'ref_Y']])\n</code></pre>"},{"location":"quickstart/#with-custom-parameters","title":"With Custom Parameters","text":"<pre><code>from src import run_same, init_optim_params, init_gurobi_params\n\n# Customize optimization parameters\noptim = init_optim_params(\n    radius=300,           # Search radius for KNN\n    knn=10,               # Number of nearest neighbors\n    max_matches=1,        # Each ref can be matched once\n    lazy_constraints=True # Memory-efficient mode\n)\n\n# Customize Gurobi parameters\ngurobi = init_gurobi_params(\n    time_limit=3600,  # 1 hour timeout\n    mip_gap=0.01      # 1% optimality gap\n)\n\nmatches, var_out = run_same(\n    ref_df=ref_df,\n    aligned_df=aligned_df,\n    commonCT=['TypeA', 'TypeB'],\n    optim_params=optim,\n    gurobi_params=gurobi\n)\n</code></pre>"},{"location":"quickstart/#large-datasets-1000-cells","title":"Large Datasets (1000+ cells)","text":"<p>For larger datasets, use sliding windows:</p> <pre><code>from src import sliding_window_matching, init_optim_params\n\noptim = init_optim_params(\n    window_size=1000,\n    overlap=250,\n    radius=250,\n    lazy_constraints=True\n)\n\nmatches = sliding_window_matching(\n    ref=ref_df,\n    moving=aligned_df,\n    commonCT=['TypeA', 'TypeB'],\n    optim_params=optim,\n    outprefix='results/'\n)\n</code></pre>"},{"location":"quickstart/#very-large-datasets-10000-cells","title":"Very Large Datasets (10,000+ cells)","text":"<p>For very large datasets, use metacells to reduce problem size:</p> <pre><code>from src import greedy_triangle_collapse, run_same, unpack_metacell_matches\n\n# Step 1: Create metacells\nmc_aligned, tri = greedy_triangle_collapse(\n    aligned_df,\n    max_metacell_size=3,  # Max cells per metacell\n    r_max=500,             # Remove long edges\n)\n\nprint(f\"Reduced from {len(aligned_df)} to {len(mc_aligned)} metacells\")\n\n# Step 2: Run SAME on metacells\nmatches, var_out = run_same(\n    ref_df=ref_df,\n    aligned_df=mc_aligned,\n    commonCT=['TypeA', 'TypeB'],\n    cell_id_col='Cell_Num'  # Metacells use Cell_Num\n)\n\n# Step 3: Unpack to individual cells\nindividual_matches = unpack_metacell_matches(\n    matches,\n    mc_aligned,\n    ref_df\n)\n</code></pre>"},{"location":"quickstart/#output-format","title":"Output Format","text":"<p>The <code>matches</code> DataFrame contains:</p> Column Description <code>aligned_idx</code> Row index in aligned_df <code>ref_idx</code> Row index in ref_df <code>X</code>, <code>Y</code> Coordinates of aligned point <code>ref_X</code>, <code>ref_Y</code> Coordinates of matched ref point <code>Aligned_Cell_Num_Old</code> Original aligned cell ID <code>Ref_Cell_Num_Old</code> Original ref cell ID <code>triangle_violation</code> Whether point is in a flipped triangle <code>run_time</code> Optimization time (seconds) <p>The <code>var_out</code> dictionary contains optimization diagnostics.</p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Algorithm Overview - Understand how SAME works</li> <li>Metacells - Learn about graph simplification</li> <li>Parameters - Full parameter reference</li> <li>Tutorials - Detailed examples</li> </ul>"},{"location":"api/helpers/","title":"Helper Functions","text":""},{"location":"api/helpers/#window-merging","title":"Window Merging","text":""},{"location":"api/helpers/#src.helpers.merge_window_matches_unique_ref","title":"<code>src.helpers.merge_window_matches_unique_ref(matches_list, cell_id_col='Cell_Num_Old')</code>","text":"<p>Merge per-window matches and enforce one-to-one matching maximizing aligned count.</p> <p>This function concatenates a list of per-window match DataFrames and returns a single DataFrame with no duplicates on either endpoint: each <code>Aligned_{cell_id_col}</code> and each <code>Ref_{cell_id_col}</code> appears at most once.</p> <p>It maximizes the number of unique <code>Aligned_{cell_id_col}</code> kept by computing a maximum-cardinality bipartite matching between <code>Aligned_{cell_id_col}</code> and <code>Ref_{cell_id_col}</code>. For duplicate occurrences of the same (aligned, ref) pair across windows, it prefers rows with <code>filtered_violation == False</code> and then smaller <code>window_id</code>.</p> <p>Required columns in each DataFrame: - 'window_id' - f'Aligned_{cell_id_col}' - f'Ref_{cell_id_col}' - 'X' - 'Y' - 'filtered_violation' (if missing, treated as True)</p> <p>Parameters:</p> Name Type Description Default <code>matches_list</code> <code>list[DataFrame]</code> <p>List of per-window matches DataFrames.</p> required <code>cell_id_col</code> <code>str</code> <p>Name of the cell ID column to use for matching.</p> <code>'Cell_Num_Old'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Maximum-cardinality one-to-one merged matches.</p>"},{"location":"api/helpers/#triangle-utilities","title":"Triangle Utilities","text":""},{"location":"api/helpers/#src.triangle_utils.compute_filtered_delaunay","title":"<code>src.triangle_utils.compute_filtered_delaunay(old_coords, alpha=0.05)</code>","text":"<p>Computes the filtered Delaunay triangulation based on an alpha shape.</p> <p>Parameters: - old_coords: array-like, shape (n_points, 2)     The coordinates of the points to triangulate. - alpha: float, optional (default=0.05)     The alpha value for the alpha shape. This value might need tuning.</p> <p>Returns: - filtered_triangles: list of simplices     The list of filtered triangles that are within the alpha shape.</p>"},{"location":"api/helpers/#violation-analysis","title":"Violation Analysis","text":""},{"location":"api/helpers/#src.violationhelper.verify_spatial_preservation","title":"<code>src.violationhelper.verify_spatial_preservation(aligned_df, ref_df, matches_df, triangle_info, tolerance=1e-06)</code>","text":"<p>Verify if spatial relationships are preserved in the matched points.</p> Parameters: <p>aligned_df : pd.DataFrame     Original aligned points with 'X', 'Y' coordinates ref_df : pd.DataFrame     Reference points with 'X', 'Y' coordinates matches_df : pd.DataFrame     Dataframe containing the matches with columns:     ['aligned_idx', 'ref_idx', 'X', 'Y', 'ref_X', 'ref_Y'] triangle_info : dict     Dictionary containing triangle information from Delaunay triangulation tolerance : float     Tolerance for floating point comparisons</p> Returns: <p>dict     Detailed report of spatial preservation violations</p>"},{"location":"api/helpers/#src.violationhelper.print_violation_report","title":"<code>src.violationhelper.print_violation_report(violations)</code>","text":"<p>Print a human-readable report of the violations.</p>"},{"location":"api/metacell_utils/","title":"Metacell Utilities","text":""},{"location":"api/metacell_utils/#src.metacell_utils.MetaCell","title":"<code>src.metacell_utils.MetaCell(original_df, params, x_col, y_col, cell_type_col, original_idx_col, metacell_idx_col, original_delaunay, metacell_df, metacell_delaunay)</code>  <code>dataclass</code>","text":"<p>Container for metacell collapse results + reproducibility metadata.</p> <p>Key conventions: - <code>original_delaunay_*</code> triangles refer to vertices in the original input. - <code>metacell_delaunay</code> triangles refer to vertices in the returned <code>metacell_df</code>   and use <code>metacell_idx_col</code> (typically 0..n_metacells-1). - <code>metacell_df[\"members\"]</code> stores a list of original IDs (values from   <code>original_idx_col</code>) that were merged into each metacell.</p>"},{"location":"api/metacell_utils/#src.metacell_utils.MetaCell-functions","title":"Functions","text":""},{"location":"api/metacell_utils/#src.metacell_utils.MetaCell.metacell_members","title":"<code>metacell_members(metacell_idx)</code>","text":"<p>Return list of original IDs that form this metacell.</p>"},{"location":"api/metacell_utils/#src.metacell_utils.MetaCell.original_delaunay_to_row_indices","title":"<code>original_delaunay_to_row_indices(triangles=None, *, on_missing='drop')</code>","text":"<p>Convert original-ID-space triangles to row indices (0..n_original-1).</p> <p>Parameters:</p> Name Type Description Default <code>triangles</code> <code>ndarray</code> <p>Triangle array in original-ID space. If None, uses self.original_delaunay.</p> <code>None</code> <code>on_missing</code> <code>('drop', 'error')</code> <p>What to do if a triangle references an original ID not present in original_df. - \"drop\": drop those triangles - \"error\": raise KeyError</p> <code>\"drop\"</code>"},{"location":"api/metacell_utils/#src.metacell_utils.MetaCell.original_delaunay_to_xy","title":"<code>original_delaunay_to_xy(triangles=None, *, on_missing='drop')</code>","text":"<p>Convert original-ID-space triangles to their X/Y coordinates.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Shape (n_triangles, 3, 2), where the last dimension is (x, y).</p>"},{"location":"api/metacell_utils/#src.metacell_utils.MetaCell.metacell_delaunay_to_xy","title":"<code>metacell_delaunay_to_xy()</code>","text":"<p>Convert metacell triangles (row-index space) to their X/Y coordinates.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Shape (n_triangles, 3, 2), where the last dimension is (x, y).</p>"},{"location":"api/metacell_utils/#src.metacell_utils.MetaCell.to_summary_dict","title":"<code>to_summary_dict()</code>","text":"<p>Small JSON-serializable-ish summary (avoids embedding full dataframes).</p>"},{"location":"api/metacell_utils/#src.metacell_utils.greedy_triangle_collapse","title":"<code>src.metacell_utils.greedy_triangle_collapse(aligned_df, max_metacell_size=3, max_iterations=1000, r_max=None, min_angle_deg=10, use_alpha_shape=False, alpha=0.05, *, original_idx_col='Cell_Num_Old', metacell_idx_col='metacell_id', x_col='X', y_col='Y', cell_type_col='cell_type', return_object=False)</code>","text":"<p>Iteratively collapse same-type triangles into metacells.</p> <p>This function simplifies a spatial graph by merging cells that form homogeneous triangles (all vertices same cell type). The result is a coarser graph with metacells that preserve boundary structure while reducing the number of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>aligned_df</code> <code>DataFrame</code> <p>Input dataframe with spatial cells. Required columns: x_col, y_col, cell_type_col, original_idx_col Optional numeric columns will be averaged (e.g., cell type proportions) Note: ID columns (Cell_Num, Cell_Num_Old, etc.) are NOT averaged;       metacells get new sequential IDs in <code>metacell_idx_col</code> (0, 1, 2, ...)</p> required <code>max_metacell_size</code> <code>int</code> <p>Maximum number of original cells in a metacell</p> <code>10</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of collapse iterations</p> <code>1000</code> <code>r_max</code> <code>float</code> <p>Maximum edge length - triangles with any edge &gt; r_max are removed</p> <code>None</code> <code>min_angle_deg</code> <code>float</code> <p>Minimum angle in degrees - triangles with smaller angles are degenerate</p> <code>10</code> <code>use_alpha_shape</code> <code>bool</code> <p>If True, filter triangles to only those within alpha shape</p> <code>False</code> <code>alpha</code> <code>float</code> <p>Alpha parameter for alpha shape (smaller = tighter boundary) Only used if use_alpha_shape=True</p> <code>0.05</code> <p>Returns:</p> Type Description <code>If return_object is False (default):</code> <p>metacell_df : pd.DataFrame     Simplified graph where each row is a metacell.     Columns: x_col, y_col, cell_type_col, size, members (list of original IDs),     metacell_idx_col (new sequential IDs), plus averaged numeric columns. metacell_delaunay : np.ndarray     Filtered Delaunay triangulation on metacells, shape (n_triangles, 3)</p> <code>If return_object is True:</code> <p>MetaCell     Object containing original_df, original_delaunay (filtered), metacell_df,     metacell_delaunay, and all parameters used.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage with edge filtering\n&gt;&gt;&gt; metacell_df, delaunay = greedy_triangle_collapse(\n...     aligned_df,\n...     max_metacell_size=10,\n...     r_max=500\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # With alpha shape filtering\n&gt;&gt;&gt; metacell_df, delaunay = greedy_triangle_collapse(\n...     aligned_df,\n...     max_metacell_size=10,\n...     r_max=500,\n...     min_angle_deg=15,\n...     use_alpha_shape=True,\n...     alpha=0.05\n... )\n</code></pre>"},{"location":"api/metacell_utils/#src.metacell_utils.unpack_metacell_matches","title":"<code>src.metacell_utils.unpack_metacell_matches(metacell_matches, metacell_aligned_df, metacell_ref_df, aligned_df=None, ref_df=None, strategy='distribute', aligned_original_idx_col=None, ref_original_idx_col=None, x_col='X', y_col='Y')</code>","text":"<p>Unpack metacell-level matches to individual cell matches.</p> <p>Handles two cases: 1. Only aligned has metacells: ref_df is individual cells (simple unpacking) 2. Both have metacells: both need unpacking using nearest neighbor</p> <p>Parameters:</p> Name Type Description Default <code>metacell_matches</code> <code>DataFrame</code> <p>Matches at metacell level (output from run_same on metacells) Must have columns: aligned_idx, ref_idx</p> required <code>metacell_aligned_df</code> <code>DataFrame</code> <p>Aligned metacell dataframe (output from greedy_triangle_collapse) Must have column: members (list of original cell indices)</p> required <code>metacell_ref_df</code> <code>DataFrame</code> <p>Reference dataframe - can be either: - Individual cells (no 'members' column): simple case - Metacells (has 'members' column): requires unpacking both sides</p> required <code>aligned_df</code> <code>DataFrame</code> <p>Original aligned cells with X, Y coordinates Required if strategy='nearest' or if ref has metacells</p> <code>None</code> <code>ref_df</code> <code>DataFrame</code> <p>Original reference cells with X, Y coordinates Required if metacell_ref_df has metacells</p> <code>None</code> <code>aligned_original_idx_col</code> <code>str</code> <p>If provided, interpret members in metacell_aligned_df as values from this column and use aligned_df.set_index(aligned_original_idx_col) to look up coordinates. If not provided, members are assumed to be valid aligned_df index values (legacy behavior).</p> <code>None</code> <code>ref_original_idx_col</code> <code>str</code> <p>Analogous to aligned_original_idx_col, for ref_df lookups when ref has metacells.</p> <code>None</code> <code>x_col</code> <code>str</code> <p>Coordinate column names in aligned_df/ref_df.</p> <code>'X'</code> <code>y_col</code> <code>str</code> <p>Coordinate column names in aligned_df/ref_df.</p> <code>'X'</code> <code>strategy</code> <code>str</code> <p>How to distribute matches: - 'distribute': all aligned members \u2192 same ref (only valid if ref is individual cells) - 'nearest': each aligned member \u2192 nearest ref member (required if both are metacells)</p> <code>'distribute'</code> <p>Returns:</p> Name Type Description <code>individual_matches</code> <code>DataFrame</code> <p>Matches at individual cell level Columns: aligned_idx, ref_idx</p> <p>Examples:</p>"},{"location":"api/metacell_utils/#src.metacell_utils.unpack_metacell_matches--case-1-only-aligned-has-metacells","title":"Case 1: Only aligned has metacells","text":"<pre><code>&gt;&gt;&gt; metacell_aligned, _ = greedy_triangle_collapse(aligned_df)\n&gt;&gt;&gt; metacell_matches, _ = run_same(metacell_aligned, ref_df, ...)\n&gt;&gt;&gt; individual_matches = unpack_metacell_matches(\n...     metacell_matches, metacell_aligned, ref_df\n... )\n</code></pre>"},{"location":"api/metacell_utils/#src.metacell_utils.unpack_metacell_matches--case-2-both-have-metacells","title":"Case 2: Both have metacells","text":"<pre><code>&gt;&gt;&gt; metacell_aligned, _ = greedy_triangle_collapse(aligned_df)\n&gt;&gt;&gt; metacell_ref, _ = greedy_triangle_collapse(ref_df)\n&gt;&gt;&gt; metacell_matches, _ = run_same(metacell_aligned, metacell_ref, ...)\n&gt;&gt;&gt; individual_matches = unpack_metacell_matches(\n...     metacell_matches, metacell_aligned, metacell_ref,\n...     aligned_df=aligned_df, ref_df=ref_df, strategy='nearest'\n... )\n</code></pre>"},{"location":"api/same/","title":"Core Functions","text":""},{"location":"api/same/#src.same.run_same","title":"<code>src.same.run_same(ref_df, aligned_df, commonCT, outprefix=None, aligned_delaunay=None, aligned_delaunay_vertex_col=None, optim_params=None, gurobi_params=None, ignore_precomputed_triangulation=False)</code>","text":"<p>Find optimal spatial matches between aligned and reference cells using MIP.</p> <p>This is the core SAME optimization function. It formulates cell matching as a Mixed Integer Program (MIP) that minimizes cell type distance and coordinate distance while preserving spatial relationships through Delaunay triangle orientation constraints.</p> <p>The function supports both \"eager\" mode (all constraints upfront) and \"lazy\" mode (constraints added on-demand via callbacks), with lazy mode being more memory-efficient for large problems.</p> <p>Parameters:</p> Name Type Description Default <code>ref_df</code> <code>DataFrame</code> <p>Reference dataset with required columns:</p> <ul> <li><code>X</code>, <code>Y</code>: Spatial coordinates</li> <li><code>cell_type</code>: Cell type annotation</li> <li>Cell type probability columns (names in <code>commonCT</code>)</li> <li>Cell ID column (name specified in optim_params['cell_id_col'])</li> </ul> required <code>aligned_df</code> <code>DataFrame or MetaCell</code> <p>Aligned/moving dataset to match against reference. Same column requirements as <code>ref_df</code>. Can be a MetaCell object.</p> required <code>commonCT</code> <code>list of str</code> <p>Names of columns containing cell type probabilities or one-hot encodings. These are used to compute cell type distance.</p> required <code>outprefix</code> <code>str</code> <p>Output directory. If provided, saves:</p> <ul> <li><code>matches_df.csv</code>: Final matched pairs</li> <li><code>aligned_df.csv</code>, <code>ref_df.csv</code>: Filtered input data</li> <li><code>var_out.npy</code>: Optimization variables and diagnostics</li> <li><code>matching_model.lp</code>: Gurobi model file</li> </ul> <code>None</code> <code>aligned_delaunay</code> <code>(array - like, shape(n_triangles, 3))</code> <p>Precomputed Delaunay triangulation. If None, computed automatically. Useful when using metacells with pre-filtered triangulation.</p> <code>None</code> <code>aligned_delaunay_vertex_col</code> <code>str</code> <p>Column name containing vertex IDs that correspond to indices in <code>aligned_delaunay</code>. Required if triangulation uses non-default IDs.</p> <code>None</code> <code>optim_params</code> <code>dict</code> <p>Optimization parameters from <code>init_optim_params()</code>. Key parameters:</p> <ul> <li><code>radius</code>: KNN search radius (default: 250)</li> <li><code>knn</code>: Number of nearest neighbors (default: 8)</li> <li><code>max_matches</code>: Max times ref can be matched (default: 1)</li> <li><code>lazy_constraints</code>: Use lazy constraint generation (default: True)</li> <li><code>delaunay_penalty</code>: Penalty for triangle flips (default: 5)</li> <li><code>no_match_penalty</code>: Penalty for unmatched cells (default: 100)</li> </ul> <code>None</code> <code>gurobi_params</code> <code>dict</code> <p>Gurobi solver parameters from <code>init_gurobi_params()</code>. Key parameters:</p> <ul> <li><code>time_limit</code>: Max solve time in seconds (default: 7200)</li> <li><code>mip_gap</code>: Optimality gap tolerance (default: 0.05)</li> <li><code>init_method</code>: MIP start method ('greedy', 'hungarian', or None)</li> </ul> <code>None</code> <code>ignore_precomputed_triangulation</code> <code>bool</code> <p>If True, compute fresh Delaunay even if precomputed one provided.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>matches_df</code> <code>DataFrame</code> <p>Matched pairs with columns:</p> <ul> <li><code>aligned_idx</code>, <code>ref_idx</code>: Row indices into filtered DataFrames</li> <li><code>X</code>, <code>Y</code>: Coordinates of aligned points</li> <li><code>ref_X</code>, <code>ref_Y</code>: Coordinates of matched reference points</li> <li><code>size</code>, <code>ref_size</code>: Metacell sizes (1 for individual cells)</li> <li><code>Ref_{cell_id_col}</code>, <code>Aligned_{cell_id_col}</code>: Original cell IDs</li> <li><code>time_limit_reached</code>: Whether solver hit time limit</li> <li><code>triangle_violation</code>: Whether point is in a flipped triangle</li> <li><code>filtered_violation</code>: Violation detected by both methods</li> <li><code>run_time</code>: Optimization time in seconds</li> </ul> <code>var_out</code> <code>dict</code> <p>Optimization diagnostics including:</p> <ul> <li><code>x</code>: Match variable values (list of 0/1)</li> <li><code>no_match_vars</code>: Unmatched penalty values</li> <li><code>penalty_vars</code>: Multi-match penalty values</li> <li><code>area_penalty_vars</code>: Triangle flip penalty values</li> <li><code>violations</code>: Spatial violation report</li> <li><code>triangle_data</code>: Triangle analysis (areas, flips)</li> <li><code>lazy_cuts_added</code>: Number of lazy constraints added</li> </ul> Notes <p>Objective Function:</p> <p>The solver minimizes:</p> <p>.. math::</p> <pre><code>\\sum_{(i,j)} c_{ij} x_{ij} + \\alpha \\sum_j p_j + \\beta \\sum_i s_i n_i + \\gamma \\sum_t w_t q_t\n</code></pre> <p>where: - :math:<code>c_{ij}</code> = cell type distance + coordinate distance - :math:<code>p_j</code> = penalty for ref j matched more than once - :math:<code>n_i</code> = penalty for aligned i not matched, weighted by size :math:<code>s_i</code> - :math:<code>q_t</code> = penalty for triangle t orientation flip, weighted by :math:<code>w_t</code></p> <p>Lazy Constraints:</p> <p>When <code>lazy_constraints=True</code>, triangle orientation constraints are added on-demand during optimization. This reduces memory from O(n\u00d7k\u00b3) to O(n) and is recommended for large problems (&gt;1000 cells).</p> <p>Space-Tearing:</p> <p>Triangle orientation flips indicate space-tearing events where the spatial relationship between cells changes (e.g., due to tissue deformation or missing cells). The <code>delaunay_penalty</code> controls how strongly these are penalized.</p> <p>Examples:</p> <p>Basic usage:</p> <pre><code>&gt;&gt;&gt; from src import run_same\n&gt;&gt;&gt; matches, var_out = run_same(\n...     ref_df=ref_df,\n...     aligned_df=aligned_df,\n...     commonCT=['TypeA', 'TypeB', 'TypeC'],\n...     outprefix='results/'\n... )\n&gt;&gt;&gt; print(f\"Found {len(matches)} matches\")\n</code></pre> <p>With custom parameters:</p> <pre><code>&gt;&gt;&gt; from src import run_same, init_optim_params, init_gurobi_params\n&gt;&gt;&gt; optim = init_optim_params(radius=500, lazy_constraints=True)\n&gt;&gt;&gt; gurobi = init_gurobi_params(time_limit=3600, mip_gap=0.01)\n&gt;&gt;&gt; matches, var_out = run_same(\n...     ref_df=ref_df,\n...     aligned_df=aligned_df,\n...     commonCT=commonCT,\n...     optim_params=optim,\n...     gurobi_params=gurobi\n... )\n</code></pre> See Also <p>sliding_window_matching : Process large datasets in windows. init_optim_params : Create optimization parameters. init_gurobi_params : Create Gurobi parameters. greedy_triangle_collapse : Create metacells for faster optimization.</p>"},{"location":"api/same/#src.same.sliding_window_matching","title":"<code>src.same.sliding_window_matching(ref, moving, commonCT=None, outprefix=None, moving_delaunay=None, moving_delaunay_vertex_col=None, optim_params=None, gurobi_params=None, ignore_precomputed_triangulation=False)</code>","text":"<p>Match cells between reference and moving datasets using a sliding window approach.</p> <p>This function divides the spatial domain into overlapping windows and runs the SAME optimization on each window. Results from overlapping regions are resolved using bipartite matching to ensure unique assignments.</p> <p>Supports resumption from partial results when <code>outprefix</code> is provided.</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>DataFrame or MetaCell</code> <p>Reference dataset with columns ['X', 'Y', 'cell_type'] plus cell type probability columns. Can also be a MetaCell object with <code>metacell_df</code> attribute.</p> required <code>moving</code> <code>DataFrame or MetaCell</code> <p>Moving/aligned dataset to be matched to reference. Same column requirements as <code>ref</code>. Can be a MetaCell object with <code>metacell_df</code> and <code>metacell_delaunay</code> attributes.</p> required <code>commonCT</code> <code>list of str</code> <p>List of cell type column names (probability/one-hot columns). If None, inferred from unique values of 'cell_type' column.</p> <code>None</code> <code>outprefix</code> <code>str</code> <p>Output directory path. If provided, intermediate results are saved and the function can resume from partial runs.</p> <code>None</code> <code>moving_delaunay</code> <code>array - like</code> <p>Precomputed Delaunay triangulation for moving data as (n, 3) array of vertex indices. If moving is a MetaCell, this is extracted automatically.</p> <code>None</code> <code>moving_delaunay_vertex_col</code> <code>str</code> <p>Column name in moving DataFrame containing vertex IDs that correspond to indices in <code>moving_delaunay</code>. Required if triangulation uses non-sequential IDs.</p> <code>None</code> <code>optim_params</code> <code>dict</code> <p>Optimization parameters. See <code>init_optim_params()</code> for defaults. Key parameters include:</p> <ul> <li><code>window_size</code>: Size of each window (default: 1000)</li> <li><code>overlap</code>: Overlap between windows (default: 250)</li> <li><code>radius</code>: KNN search radius (default: 250)</li> <li><code>knn</code>: Number of nearest neighbors (default: 8)</li> <li><code>lazy_constraints</code>: Use memory-efficient constraints (default: True)</li> </ul> <code>None</code> <code>gurobi_params</code> <code>dict</code> <p>Gurobi solver parameters. See <code>init_gurobi_params()</code> for defaults.</p> <code>None</code> <code>ignore_precomputed_triangulation</code> <code>bool</code> <p>If True, compute fresh Delaunay triangulation even if precomputed one is available.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Matched pairs with columns:</p> <ul> <li><code>aligned_idx</code>, <code>ref_idx</code>: Integer indices into input DataFrames</li> <li><code>X</code>, <code>Y</code>: Coordinates of aligned points</li> <li><code>ref_X</code>, <code>ref_Y</code>: Coordinates of matched reference points</li> <li>Cell type probability columns</li> <li><code>size</code>, <code>ref_size</code>: Metacell sizes (if applicable)</li> <li><code>window_id</code>: Which window the match came from</li> <li><code>time_limit_reached</code>: Whether solver hit time limit</li> <li><code>triangle_violation</code>: Whether point is in a flipped triangle</li> <li><code>run_time</code>: Optimization time for the window</li> </ul> <p>Examples:</p> <p>Basic usage:</p> <pre><code>&gt;&gt;&gt; from src import sliding_window_matching, init_optim_params\n&gt;&gt;&gt; matches = sliding_window_matching(\n...     ref=ref_df,\n...     moving=aligned_df,\n...     commonCT=['TypeA', 'TypeB', 'TypeC'],\n...     outprefix='results/'\n... )\n</code></pre> <p>With custom parameters:</p> <pre><code>&gt;&gt;&gt; optim = init_optim_params(window_size=500, overlap=100, radius=300)\n&gt;&gt;&gt; matches = sliding_window_matching(\n...     ref=ref_df,\n...     moving=aligned_df,\n...     optim_params=optim\n... )\n</code></pre> <p>With metacells:</p> <pre><code>&gt;&gt;&gt; from src import MetaCell\n&gt;&gt;&gt; mc_aligned = MetaCell(aligned_df, max_metacell_size=10)\n&gt;&gt;&gt; matches = sliding_window_matching(ref=ref_df, moving=mc_aligned)\n</code></pre> See Also <p>run_same : Core optimization for a single region. init_optim_params : Create optimization parameter dictionary. init_gurobi_params : Create Gurobi parameter dictionary. merge_window_matches_unique_ref : Merge overlapping window results.</p>"},{"location":"api/same/#src.same.init_optim_params","title":"<code>src.same.init_optim_params(**overrides)</code>","text":"<p>Create default optimization parameters for SAME matching.</p> <p>Returns a dictionary of parameters controlling the matching problem formulation, spatial constraints, and sliding window behavior. Use keyword arguments to override specific defaults.</p> <p>Parameters:</p> Name Type Description Default <code>**overrides</code> <code>dict</code> <p>Keyword arguments to override default values.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of optimization parameters with the following keys:</p> <p>Sliding window parameters:</p> <ul> <li><code>window_size</code> : int, default=1000     Size of each window in coordinate units.</li> <li><code>overlap</code> : int, default=250     Overlap between adjacent windows.</li> <li><code>min_cells_per_window</code> : int, default=10     Minimum cells required to process a window.</li> </ul> <p>Matching problem parameters:</p> <ul> <li><code>max_matches</code> : int, default=1     Maximum times a reference point can be matched.</li> <li><code>ref_metacell_match_multiplier</code> : int or None, default=None     For metacells, multiplier for max_matches. None = use max size.</li> <li><code>radius</code> : float, default=250     Search radius for finding KNN candidates.</li> <li><code>knn</code> : int, default=8     Number of nearest neighbors to consider.</li> </ul> <p>Objective function coefficients:</p> <ul> <li><code>penalty_coeff</code> : float, default=100     Penalty for reference point matched more than once.</li> <li><code>no_match_penalty</code> : float, default=100     Penalty for unmatched aligned point (per cell).</li> <li><code>delaunay_penalty</code> : float, default=5     Penalty for triangle orientation flip (space-tearing).</li> <li><code>dist_ct_coeff</code> : float, default=1     Weight for cell type distance in objective.</li> </ul> <p>Output labeling:</p> <ul> <li><code>cell_id_col</code> : str, default='Cell_Num_Old'     Column name for cell identifiers.</li> </ul> <p>Constraint/behavior flags:</p> <ul> <li><code>hard_spatial_constraints</code> : bool, default=False     If True, strictly forbid triangle flips (no soft penalty).</li> <li><code>ignore_same_type_triangles</code> : bool, default=True     If True, skip constraints for triangles with homogeneous cell types.</li> <li><code>ignore_knn_if_matched</code> : bool, default=False     If True, use cell-type priority in KNN search.</li> <li><code>lazy_constraints</code> : bool, default=True     If True, add spatial constraints lazily (memory efficient).</li> </ul> <p>Triangle quality filtering:</p> <ul> <li><code>min_angle_deg</code> : float, default=15     Filter out thin triangles with minimum angle below this threshold.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; params = init_optim_params(radius=500, knn=10, lazy_constraints=True)\n&gt;&gt;&gt; params['radius']\n500\n</code></pre> See Also <p>init_gurobi_params : Create Gurobi solver parameters. run_same : Main optimization function using these parameters. sliding_window_matching : Sliding window approach for large datasets.</p>"},{"location":"api/same/#src.same.init_gurobi_params","title":"<code>src.same.init_gurobi_params(**overrides)</code>","text":"<p>Create default Gurobi solver parameters for SAME optimization.</p> <p>Returns a dictionary of Gurobi-related parameters that control solver behavior, time limits, and lazy constraint generation. Use keyword arguments to override specific defaults.</p> <p>Parameters:</p> Name Type Description Default <code>**overrides</code> <code>dict</code> <p>Keyword arguments to override default values.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of Gurobi parameters with the following keys:</p> <p>Core solve controls:</p> <ul> <li><code>time_limit</code> : int, default=7200     Maximum solve time in seconds (2 hours).</li> <li><code>mip_gap</code> : float, default=0.05     MIP optimality gap tolerance (5%).</li> </ul> <p>Gurobi tuning knobs:</p> <ul> <li><code>mip_focus</code> : int, default=2     MIPFocus parameter (2 = focus on proving optimality).</li> <li><code>cuts</code> : int, default=2     Cut generation aggressiveness (0=none to 3=aggressive).</li> <li><code>heuristics</code> : float, default=0.1     Fraction of time spent on heuristics (0.0-1.0).</li> </ul> <p>MIP start / initialization:</p> <ul> <li><code>init_method</code> : str or None, default=None     Method for warm-starting the solver:<ul> <li>None: no initialization</li> <li>'greedy': fast greedy assignment</li> <li>'hungarian': optimal assignment (requires max_matches=1)</li> </ul> </li> <li><code>init_big_m</code> : float, default=1e9     Large cost for forbidden pairs in Hungarian init.</li> <li><code>init_hungarian_max_n</code> : int, default=5000     Skip Hungarian init if n_aligned + n_ref exceeds this.</li> </ul> <p>Lazy constraints:</p> <ul> <li><code>lazy_max_cuts</code> : int or None, default=None     Global cap on lazy cuts added (None = unlimited).</li> <li><code>lazy_allowed_flip_fraction</code> : float, default=0.05     Allowed fraction of flipped triangles before adding cuts.</li> <li><code>lazy_max_cuts_per_incumbent</code> : int, default=1000     Max cuts added per incumbent solution.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; params = init_gurobi_params(time_limit=3600, mip_gap=0.01)\n&gt;&gt;&gt; params['time_limit']\n3600\n</code></pre> See Also <p>init_optim_params : Create optimization parameters. run_same : Main optimization function using these parameters.</p>"},{"location":"concepts/algorithm/","title":"Algorithm Overview","text":"<p>SAME formulates cell matching as a Mixed Integer Program (MIP) that balances cell type similarity with spatial consistency.</p>"},{"location":"concepts/algorithm/#problem-formulation","title":"Problem Formulation","text":"<p>Given: - Reference cells \\(R = \\{r_1, ..., r_n\\}\\) with coordinates and cell type probabilities - Aligned/moving cells \\(A = \\{a_1, ..., a_m\\}\\) to be matched to reference - Delaunay triangulation \\(T\\) on the aligned cells</p> <p>Find: Binary match variables \\(x_{ij} \\in \\{0,1\\}\\) indicating whether aligned cell \\(a_i\\) matches reference cell \\(r_j\\).</p>"},{"location":"concepts/algorithm/#objective-function","title":"Objective Function","text":"<p>SAME minimizes:</p> \\[\\min \\sum_{(i,j) \\in P} c_{ij} x_{ij} + \\alpha \\sum_j p_j + \\beta \\sum_i s_i n_i + \\gamma \\sum_t w_t q_t\\] <p>Where: - \\(c_{ij}\\) = cell type distance + coordinate distance between \\(a_i\\) and \\(r_j\\) - \\(p_j\\) = penalty when reference cell \\(r_j\\) is matched more than once - \\(n_i\\) = penalty when aligned cell \\(a_i\\) is not matched (weighted by size \\(s_i\\)) - \\(q_t\\) = penalty when triangle \\(t\\) flips orientation (weighted by \\(w_t\\))</p>"},{"location":"concepts/algorithm/#constraints","title":"Constraints","text":""},{"location":"concepts/algorithm/#1-valid-pairs-knn","title":"1. Valid Pairs (KNN)","text":"<p>Only allow matches between nearby cells: - For each aligned cell, find K nearest reference cells within radius \\(R\\) - Creates the set of valid pairs \\(P \\subset A \\times R\\)</p>"},{"location":"concepts/algorithm/#2-one-match-per-aligned-cell","title":"2. One Match per Aligned Cell","text":"<p>Each aligned cell can match at most one reference cell:</p> \\[\\sum_{j: (i,j) \\in P} x_{ij} \\leq 1 \\quad \\forall i \\in A\\]"},{"location":"concepts/algorithm/#3-max-matches-per-reference-cell","title":"3. Max Matches per Reference Cell","text":"<p>Each reference cell can be matched at most \\(M\\) times (typically \\(M=1\\)):</p> \\[\\sum_{i: (i,j) \\in P} x_{ij} \\leq M \\quad \\forall j \\in R\\]"},{"location":"concepts/algorithm/#4-spatial-constraints-triangle-orientation","title":"4. Spatial Constraints (Triangle Orientation)","text":"<p>For each Delaunay triangle \\((a, b, c)\\) in the aligned data:</p> <ul> <li>Compute source orientation: \\(\\text{sign}((b-a) \\times (c-a))\\)</li> <li>If all vertices are matched to \\((r_a, r_b, r_c)\\):</li> <li>Compute target orientation: \\(\\text{sign}((r_b-r_a) \\times (r_c-r_a))\\)</li> <li>If orientations differ \u2192 triangle flip \u2192 add penalty \\(q_t\\)</li> </ul>"},{"location":"concepts/algorithm/#space-tearing-transforms","title":"Space-Tearing Transforms","text":"<p>Unlike rigid registration, SAME allows space-tearing: situations where the spatial relationship between cells changes.</p> <p></p> <p>Space-tearing occurs when: - A cell is missing in one section - Cells appear in different relative positions - Tissue has deformed non-rigidly</p> <p>SAME handles this by: 1. Penalizing (not forbidding) triangle orientation flips 2. Allowing controlled violations with soft constraints 3. Using <code>delaunay_penalty</code> to tune flip tolerance</p>"},{"location":"concepts/algorithm/#lazy-constraint-generation","title":"Lazy Constraint Generation","text":"<p>For large problems, the number of triangle constraints is \\(O(n \\times k^3)\\) where \\(k\\) is the KNN. This can be memory-prohibitive.</p> <p>Lazy mode adds constraints on-demand: 1. Start with no triangle constraints 2. Find optimal solution without spatial constraints 3. Check for triangle flips in the solution 4. Add violated constraints as \"lazy cuts\" 5. Re-optimize with new constraints 6. Repeat until no more violations (or within tolerance)</p> <p>Benefits: - Memory: \\(O(n)\\) instead of \\(O(n \\times k^3)\\) - Speed: Often much faster since most constraints are never needed - Control: <code>lazy_allowed_flip_fraction</code> lets you accept some flips</p>"},{"location":"concepts/algorithm/#algorithm-steps","title":"Algorithm Steps","text":"<ol> <li>Preprocessing</li> <li>Filter cells to those with valid KNN pairs within radius</li> <li>Build Delaunay triangulation on aligned cells</li> <li> <p>Filter triangles by edge length and angle quality</p> </li> <li> <p>Model Construction</p> </li> <li>Create binary match variables \\(x_{ij}\\)</li> <li>Add basic constraints (one-match, max-match)</li> <li>Add spatial constraints (eager or lazy mode)</li> <li> <p>Set objective function</p> </li> <li> <p>Optimization</p> </li> <li>Use Gurobi MIP solver</li> <li>If lazy mode: use callback for constraint generation</li> <li> <p>Stop at time limit or optimality gap</p> </li> <li> <p>Post-processing</p> </li> <li>Extract matches from solution</li> <li>Verify spatial preservation</li> <li>Report triangle violations</li> </ol>"},{"location":"concepts/algorithm/#sliding-window","title":"Sliding Window","text":"<p>For very large spatial regions, SAME processes data in overlapping windows:</p> <ol> <li>Divide region into grid of windows (size \u00d7 size)</li> <li>Add overlap between adjacent windows</li> <li>Process each window independently</li> <li>Merge results using Hopcroft-Karp bipartite matching</li> <li>Resolve conflicts in overlap regions</li> </ol>"},{"location":"concepts/algorithm/#metacells","title":"Metacells","text":"<p>For datasets with many same-type cells, metacells reduce problem size:</p> <ol> <li>Build Delaunay triangulation on cells</li> <li>Find triangles where all vertices have same cell type</li> <li>Collapse these \"homogeneous\" triangles into metacells</li> <li>Run SAME on metacells</li> <li>Unpack matches to individual cells</li> </ol> <p>See Metacells for details.</p>"},{"location":"concepts/metacells/","title":"Metacells","text":"<p>Metacells are a graph simplification technique that reduces problem size while preserving spatial constraints.</p>"},{"location":"concepts/metacells/#motivation","title":"Motivation","text":"<p>In spatial omics data, regions with homogeneous cell types have many same-type triangles in the Delaunay triangulation. These triangles:</p> <ol> <li>Provide redundant spatial constraints</li> <li>Increase memory and computation time</li> <li>Can be safely collapsed without losing important structure</li> </ol>"},{"location":"concepts/metacells/#how-metacells-work","title":"How Metacells Work","text":""},{"location":"concepts/metacells/#step-1-build-delaunay-triangulation","title":"Step 1: Build Delaunay Triangulation","text":"<p>Compute Delaunay triangulation on the input cells.</p>"},{"location":"concepts/metacells/#step-2-identify-same-type-triangles","title":"Step 2: Identify Same-Type Triangles","text":"<p>Find triangles where all three vertices have the same cell type:</p> <pre><code>   A (TypeA)\n   /\\\n  /  \\\n /    \\\nB------C\n(TypeA) (TypeA)\n</code></pre> <p>These triangles represent \"homogeneous\" regions.</p>"},{"location":"concepts/metacells/#step-3-collapse-triangles","title":"Step 3: Collapse Triangles","text":"<p>Iteratively merge same-type triangles:</p> <ol> <li>Select a same-type triangle</li> <li>Check if merging would exceed <code>max_metacell_size</code></li> <li>If valid, merge the three cells into one metacell</li> <li>Update coordinates to centroid</li> <li>Average cell type probabilities</li> <li>Track original cell members</li> <li>Repeat until no more valid merges</li> </ol>"},{"location":"concepts/metacells/#step-4-update-triangulation","title":"Step 4: Update Triangulation","text":"<p>Recompute Delaunay on metacells. The new triangulation: - Has fewer vertices (metacells instead of cells) - Preserves boundary structure (mixed-type triangles kept) - Reduces constraint count significantly</p>"},{"location":"concepts/metacells/#usage","title":"Usage","text":""},{"location":"concepts/metacells/#basic-metacell-creation","title":"Basic Metacell Creation","text":"<pre><code>from src import greedy_triangle_collapse\n\nmetacell_df, metacell_delaunay = greedy_triangle_collapse(\n    aligned_df,\n    max_metacell_size=3,  # Max cells per metacell\n    r_max=500,             # Remove edges &gt; 500 units\n    min_angle_deg=15,      # Remove thin triangles\n)\n\nprint(f\"Reduced from {len(aligned_df)} to {len(metacell_df)} metacells\")\n</code></pre>"},{"location":"concepts/metacells/#with-alpha-shape-filtering","title":"With Alpha Shape Filtering","text":"<pre><code>metacell_df, metacell_delaunay = greedy_triangle_collapse(\n    aligned_df,\n    max_metacell_size=3,\n    r_max=500,\n    use_alpha_shape=True,  # Filter to alpha complex\n    alpha=0.05,            # Smaller = tighter boundary\n)\n</code></pre>"},{"location":"concepts/metacells/#using-metacell-object","title":"Using MetaCell Object","text":"<p>For more control, use <code>return_object=True</code>:</p> <pre><code>mc = greedy_triangle_collapse(aligned_df, max_metacell_size=3, return_object=True)\n\n# Access results\nprint(f\"Original: {len(mc.original_df)} cells\")\nprint(f\"Metacells: {len(mc.metacell_df)} metacells\")\nprint(f\"Original triangles: {len(mc.original_delaunay)}\")\nprint(f\"Metacell triangles: {len(mc.metacell_delaunay)}\")\n\n# Get members of a metacell\nmembers = mc.metacell_members(0)\nprint(f\"Metacell 0 contains cells: {members}\")\n</code></pre>"},{"location":"concepts/metacells/#matching-with-metacells","title":"Matching with Metacells","text":""},{"location":"concepts/metacells/#case-1-metacells-on-aligned-only-recommended","title":"Case 1: Metacells on Aligned Only (Recommended)","text":"<pre><code>from src import greedy_triangle_collapse, run_same, unpack_metacell_matches\n\n# Create metacells for aligned data\nmc_aligned, _ = greedy_triangle_collapse(aligned_df, max_metacell_size=3)\n\n# Run SAME: metacells vs individual ref cells\nmatches, var_out = run_same(\n    ref_df=ref_df,              # Individual cells\n    aligned_df=mc_aligned,      # Metacells\n    commonCT=commonCT,\n    cell_id_col='Cell_Num',     # Metacells use Cell_Num\n)\n\n# Unpack to individual cells\nindividual_matches = unpack_metacell_matches(\n    matches, mc_aligned, ref_df\n)\n</code></pre>"},{"location":"concepts/metacells/#case-2-metacells-on-both-sides-fastest","title":"Case 2: Metacells on Both Sides (Fastest)","text":"<pre><code># Create metacells for both datasets\nmc_aligned, _ = greedy_triangle_collapse(aligned_df, max_metacell_size=3)\nmc_ref, _ = greedy_triangle_collapse(ref_df, max_metacell_size=3)\n\n# Run SAME on metacells\nmatches, var_out = run_same(\n    ref_df=mc_ref,\n    aligned_df=mc_aligned,\n    commonCT=commonCT,\n    cell_id_col='Cell_Num',\n)\n\n# Unpack using nearest neighbor strategy\nindividual_matches = unpack_metacell_matches(\n    matches, mc_aligned, mc_ref,\n    aligned_df=aligned_df,\n    ref_df=ref_df,\n    strategy='nearest'  # Required for both-metacells case\n)\n</code></pre>"},{"location":"concepts/metacells/#unpacking-strategies","title":"Unpacking Strategies","text":""},{"location":"concepts/metacells/#strategydistribute-default","title":"<code>strategy='distribute'</code> (default)","text":"<p>All cells in an aligned metacell are matched to the same reference cell/metacell.</p> <ul> <li>Simple and fast</li> <li>Works when reference has individual cells</li> <li>May create many-to-one matches</li> </ul>"},{"location":"concepts/metacells/#strategynearest","title":"<code>strategy='nearest'</code>","text":"<p>Each aligned cell is matched to its nearest reference cell within the matched metacells.</p> <ul> <li>Required when both sides have metacells</li> <li>Creates more natural one-to-one matches</li> <li>Slightly slower (requires distance computation)</li> </ul>"},{"location":"concepts/metacells/#parameters","title":"Parameters","text":"Parameter Default Description <code>max_metacell_size</code> 3 Maximum cells per metacell <code>max_iterations</code> 1000 Maximum collapse iterations <code>r_max</code> None Maximum edge length <code>min_angle_deg</code> 10 Minimum triangle angle (degrees) <code>use_alpha_shape</code> False Filter to alpha complex <code>alpha</code> 0.05 Alpha parameter (smaller = tighter)"},{"location":"concepts/metacells/#tips","title":"Tips","text":"<ol> <li>Choose <code>max_metacell_size</code> based on cell density: Higher density \u2192 larger metacells OK</li> <li>Set <code>r_max</code> to typical cell spacing: Removes long edges across gaps</li> <li>Use <code>min_angle_deg=15</code>: Filters degenerate thin triangles</li> <li>Enable <code>use_alpha_shape</code>: Helps with complex boundaries</li> <li>Monitor reduction ratio: Aim for 3-10x reduction</li> </ol>"},{"location":"concepts/parameters/","title":"Parameter Reference","text":"<p>Complete reference for all SAME parameters.</p>"},{"location":"concepts/parameters/#optimization-parameters-init_optim_params","title":"Optimization Parameters (<code>init_optim_params</code>)","text":"<p>These parameters control the matching problem formulation.</p>"},{"location":"concepts/parameters/#sliding-window","title":"Sliding Window","text":"Parameter Default Description <code>window_size</code> 1000 Size of each window in coordinate units <code>overlap</code> 250 Overlap between adjacent windows <code>min_cells_per_window</code> 10 Minimum cells required to process a window"},{"location":"concepts/parameters/#matching-problem","title":"Matching Problem","text":"Parameter Default Description <code>max_matches</code> 1 Maximum times a reference point can be matched <code>ref_metacell_match_multiplier</code> None For ref metacells, multiplier for max_matches. None = use max metacell size <code>radius</code> 250 Search radius for finding KNN candidates <code>knn</code> 8 Number of nearest neighbors to consider"},{"location":"concepts/parameters/#objective-coefficients","title":"Objective Coefficients","text":"Parameter Default Description <code>penalty_coeff</code> 100 Penalty for reference matched more than once <code>no_match_penalty</code> 100 Penalty for unmatched aligned point (per cell) <code>delaunay_penalty</code> 5 Penalty for triangle orientation flip <code>dist_ct_coeff</code> 1 Weight for cell type distance in objective <p>Tuning penalties</p> <ul> <li>Increase <code>delaunay_penalty</code> to discourage space-tearing</li> <li>Decrease <code>delaunay_penalty</code> to allow more flexible matching</li> <li>Increase <code>no_match_penalty</code> to encourage more matches</li> </ul>"},{"location":"concepts/parameters/#constraint-flags","title":"Constraint Flags","text":"Parameter Default Description <code>hard_spatial_constraints</code> False If True, strictly forbid triangle flips <code>ignore_same_type_triangles</code> True Skip constraints for homogeneous triangles <code>ignore_knn_if_matched</code> False Use cell-type priority in KNN search <code>lazy_constraints</code> True Add spatial constraints lazily (memory efficient)"},{"location":"concepts/parameters/#triangle-quality","title":"Triangle Quality","text":"Parameter Default Description <code>min_angle_deg</code> 15 Filter triangles with minimum angle below threshold"},{"location":"concepts/parameters/#output","title":"Output","text":"Parameter Default Description <code>cell_id_col</code> 'Cell_Num_Old' Column name for cell identifiers"},{"location":"concepts/parameters/#gurobi-parameters-init_gurobi_params","title":"Gurobi Parameters (<code>init_gurobi_params</code>)","text":"<p>These parameters control the Gurobi solver.</p>"},{"location":"concepts/parameters/#core-controls","title":"Core Controls","text":"Parameter Default Description <code>time_limit</code> 7200 Maximum solve time in seconds (2 hours) <code>mip_gap</code> 0.05 MIP optimality gap tolerance (5%)"},{"location":"concepts/parameters/#solver-tuning","title":"Solver Tuning","text":"Parameter Default Description <code>mip_focus</code> 2 MIPFocus: 1=find solutions, 2=prove optimality <code>cuts</code> 2 Cut generation (0=none to 3=aggressive) <code>heuristics</code> 0.1 Fraction of time on heuristics (0.0-1.0)"},{"location":"concepts/parameters/#mip-start","title":"MIP Start","text":"Parameter Default Description <code>init_method</code> None Warm-start method: None, 'greedy', or 'hungarian' <code>init_big_m</code> 1e9 Large cost for forbidden pairs in Hungarian init <code>init_hungarian_max_n</code> 5000 Skip Hungarian if n_aligned + n_ref exceeds this"},{"location":"concepts/parameters/#lazy-constraints","title":"Lazy Constraints","text":"Parameter Default Description <code>lazy_max_cuts</code> None Global cap on lazy cuts (None = unlimited) <code>lazy_allowed_flip_fraction</code> 0.05 Allowed fraction of flipped triangles <code>lazy_max_cuts_per_incumbent</code> 1000 Max cuts per incumbent solution"},{"location":"concepts/parameters/#metacell-parameters-greedy_triangle_collapse","title":"Metacell Parameters (<code>greedy_triangle_collapse</code>)","text":"Parameter Default Description <code>max_metacell_size</code> 3 Maximum cells per metacell <code>max_iterations</code> 1000 Maximum collapse iterations <code>r_max</code> None Maximum edge length (removes long edges) <code>min_angle_deg</code> 10 Minimum triangle angle in degrees <code>use_alpha_shape</code> False Filter triangles to alpha complex <code>alpha</code> 0.05 Alpha parameter (smaller = tighter boundary)"},{"location":"concepts/parameters/#common-configurations","title":"Common Configurations","text":""},{"location":"concepts/parameters/#small-dataset-1000-cells","title":"Small Dataset (&lt;1000 cells)","text":"<pre><code>optim = init_optim_params(\n    radius=500,\n    knn=10,\n    lazy_constraints=False,  # Eager mode OK for small data\n)\ngurobi = init_gurobi_params(\n    time_limit=1800,  # 30 minutes\n    mip_gap=0.01,     # 1% gap\n)\n</code></pre>"},{"location":"concepts/parameters/#medium-dataset-1000-10000-cells","title":"Medium Dataset (1000-10000 cells)","text":"<pre><code>optim = init_optim_params(\n    window_size=1000,\n    overlap=250,\n    radius=250,\n    knn=8,\n    lazy_constraints=True,\n)\ngurobi = init_gurobi_params(\n    time_limit=3600,  # 1 hour per window\n    mip_gap=0.05,\n)\n</code></pre>"},{"location":"concepts/parameters/#large-dataset-10000-cells","title":"Large Dataset (&gt;10000 cells)","text":"<pre><code># Use metacells\nmc_aligned, _ = greedy_triangle_collapse(\n    aligned_df,\n    max_metacell_size=3,\n    r_max=500,\n)\n\noptim = init_optim_params(\n    window_size=1000,\n    overlap=250,\n    radius=250,\n    lazy_constraints=True,\n    cell_id_col='Cell_Num',\n)\ngurobi = init_gurobi_params(\n    time_limit=7200,\n    mip_gap=0.05,\n    init_method='greedy',  # Warm start\n)\n</code></pre>"},{"location":"concepts/parameters/#high-accuracy-more-time","title":"High Accuracy (more time)","text":"<pre><code>optim = init_optim_params(\n    radius=300,\n    knn=15,\n    delaunay_penalty=50,  # Strong spatial preservation\n    lazy_constraints=True,\n)\ngurobi = init_gurobi_params(\n    time_limit=14400,  # 4 hours\n    mip_gap=0.01,      # 1% gap\n    mip_focus=2,       # Focus on optimality\n)\n</code></pre>"},{"location":"concepts/parameters/#fast-approximate-less-time","title":"Fast Approximate (less time)","text":"<pre><code>optim = init_optim_params(\n    radius=200,\n    knn=5,\n    delaunay_penalty=1,  # Allow more space-tearing\n    lazy_constraints=True,\n)\ngurobi = init_gurobi_params(\n    time_limit=600,    # 10 minutes\n    mip_gap=0.10,      # 10% gap OK\n    mip_focus=1,       # Find solutions quickly\n    heuristics=0.3,    # More heuristics\n)\n</code></pre>"},{"location":"tutorials/basic_usage/","title":"Basic Usage Tutorial","text":"<p>This tutorial walks through a complete SAME analysis on a small dataset.</p>"},{"location":"tutorials/basic_usage/#setup","title":"Setup","text":"<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Add SAME to path\nimport sys\nsys.path.insert(0, str(Path.cwd().parent))\n\nfrom src import run_same, init_optim_params, init_gurobi_params\n</code></pre>"},{"location":"tutorials/basic_usage/#load-example-data","title":"Load Example Data","text":"<pre><code># Download example data (if not already present)\nimport pooch\n\nDATA_URL = \"https://zenodo.org/record/XXXXXX/files/\"\ndata_cache = pooch.create(\n    path=pooch.os_cache(\"same_data\"),\n    base_url=DATA_URL,\n    registry={\n        \"example_ref.csv\": \"sha256:...\",\n        \"example_aligned.csv\": \"sha256:...\",\n    }\n)\n\nref_df = pd.read_csv(data_cache.fetch(\"example_ref.csv\"))\naligned_df = pd.read_csv(data_cache.fetch(\"example_aligned.csv\"))\n\nprint(f\"Reference: {len(ref_df)} cells\")\nprint(f\"Aligned: {len(aligned_df)} cells\")\n</code></pre>"},{"location":"tutorials/basic_usage/#visualize-input-data","title":"Visualize Input Data","text":"<pre><code>fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Reference\nax = axes[0]\nfor ct in ref_df['cell_type'].unique():\n    subset = ref_df[ref_df['cell_type'] == ct]\n    ax.scatter(subset['X'], subset['Y'], label=ct, s=10, alpha=0.7)\nax.set_title('Reference')\nax.legend()\n\n# Aligned\nax = axes[1]\nfor ct in aligned_df['cell_type'].unique():\n    subset = aligned_df[aligned_df['cell_type'] == ct]\n    ax.scatter(subset['X'], subset['Y'], label=ct, s=10, alpha=0.7)\nax.set_title('Aligned (to be matched)')\nax.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"tutorials/basic_usage/#run-same","title":"Run SAME","text":"<pre><code># Define cell type columns\ncommonCT = ['TypeA', 'TypeB', 'TypeC']\n\n# Configure parameters\noptim = init_optim_params(\n    radius=300,           # Search radius\n    knn=10,               # Nearest neighbors\n    lazy_constraints=True # Memory efficient\n)\n\ngurobi = init_gurobi_params(\n    time_limit=1800,  # 30 minutes max\n    mip_gap=0.05      # 5% gap tolerance\n)\n\n# Run optimization\nmatches, var_out = run_same(\n    ref_df=ref_df,\n    aligned_df=aligned_df,\n    commonCT=commonCT,\n    optim_params=optim,\n    gurobi_params=gurobi,\n    outprefix='results/'\n)\n\nprint(f\"Found {len(matches)} matches\")\n</code></pre>"},{"location":"tutorials/basic_usage/#analyze-results","title":"Analyze Results","text":"<pre><code># Match rate\nprint(f\"Match rate: {len(matches) / len(aligned_df) * 100:.1f}%\")\n\n# Cell type accuracy\nmatches['type_match'] = (\n    matches['aligned_idx'].map(aligned_df.set_index(aligned_df.index)['cell_type']) ==\n    matches['ref_idx'].map(ref_df.set_index(ref_df.index)['cell_type'])\n)\nprint(f\"Cell type accuracy: {matches['type_match'].mean() * 100:.1f}%\")\n\n# Spatial violations\nn_violations = matches['triangle_violation'].sum()\nprint(f\"Triangle violations: {n_violations} ({n_violations / len(matches) * 100:.1f}%)\")\n</code></pre>"},{"location":"tutorials/basic_usage/#visualize-matches","title":"Visualize Matches","text":"<pre><code>fig, ax = plt.subplots(figsize=(10, 10))\n\n# Plot reference\nax.scatter(ref_df['X'], ref_df['Y'], c='blue', s=20, alpha=0.3, label='Reference')\n\n# Plot aligned\nax.scatter(aligned_df['X'], aligned_df['Y'], c='red', s=20, alpha=0.3, label='Aligned')\n\n# Draw match lines\nfor _, row in matches.iterrows():\n    ax.plot([row['X'], row['ref_X']], [row['Y'], row['ref_Y']],\n            'g-', alpha=0.3, linewidth=0.5)\n\nax.set_title(f'SAME Matches (n={len(matches)})')\nax.legend()\nplt.show()\n</code></pre>"},{"location":"tutorials/basic_usage/#save-results","title":"Save Results","text":"<pre><code># Save matches\nmatches.to_csv('results/matches.csv', index=False)\n\n# Create aligned coordinates (SAME_X, SAME_Y)\naligned_with_same = aligned_df.copy()\naligned_with_same = aligned_with_same.merge(\n    matches[['aligned_idx', 'ref_X', 'ref_Y']],\n    left_index=True, right_on='aligned_idx', how='left'\n)\naligned_with_same.rename(columns={'ref_X': 'SAME_X', 'ref_Y': 'SAME_Y'}, inplace=True)\n\n# For unmatched cells, keep original coordinates\naligned_with_same['SAME_X'] = aligned_with_same['SAME_X'].fillna(aligned_with_same['X'])\naligned_with_same['SAME_Y'] = aligned_with_same['SAME_Y'].fillna(aligned_with_same['Y'])\n\naligned_with_same.to_csv('results/aligned_with_same_coords.csv', index=False)\n</code></pre>"},{"location":"tutorials/basic_usage/#next-steps","title":"Next Steps","text":"<ul> <li>Large Datasets Tutorial - Handle 10,000+ cells</li> <li>Synthetic Benchmarks - Validate with ground truth</li> </ul>"},{"location":"tutorials/large_datasets/","title":"Large Datasets Tutorial","text":"<p>This tutorial covers techniques for handling datasets with 10,000+ cells.</p>"},{"location":"tutorials/large_datasets/#approach-overview","title":"Approach Overview","text":"<p>For large datasets, we combine two strategies:</p> <ol> <li>Metacells: Reduce cell count by merging same-type triangles</li> <li>Sliding Windows: Process regions independently and merge</li> </ol>"},{"location":"tutorials/large_datasets/#option-1-metacells-only","title":"Option 1: Metacells Only","text":"<p>Best for: 5,000 - 50,000 cells with spatial homogeneity.</p> <pre><code>from src import greedy_triangle_collapse, run_same, unpack_metacell_matches\nfrom src import init_optim_params, init_gurobi_params\n\n# Step 1: Create metacells\nprint(\"Creating metacells...\")\nmc_aligned, tri = greedy_triangle_collapse(\n    aligned_df,\n    max_metacell_size=3,\n    r_max=500,           # Remove edges &gt; 500 units\n    min_angle_deg=15,    # Remove thin triangles\n)\nprint(f\"Reduced: {len(aligned_df)} -&gt; {len(mc_aligned)} metacells\")\n\n# Step 2: Configure and run SAME\noptim = init_optim_params(\n    radius=300,\n    knn=10,\n    lazy_constraints=True,\n    cell_id_col='Cell_Num',  # Metacells use Cell_Num\n)\n\ngurobi = init_gurobi_params(\n    time_limit=7200,\n    mip_gap=0.05,\n    init_method='greedy',\n)\n\nmatches, var_out = run_same(\n    ref_df=ref_df,\n    aligned_df=mc_aligned,\n    commonCT=commonCT,\n    optim_params=optim,\n    gurobi_params=gurobi,\n)\n\n# Step 3: Unpack to individual cells\nindividual_matches = unpack_metacell_matches(\n    matches, mc_aligned, ref_df\n)\nprint(f\"Individual matches: {len(individual_matches)}\")\n</code></pre>"},{"location":"tutorials/large_datasets/#option-2-sliding-windows-only","title":"Option 2: Sliding Windows Only","text":"<p>Best for: Wide spatial regions where metacells aren't effective.</p> <pre><code>from src import sliding_window_matching, init_optim_params\n\noptim = init_optim_params(\n    window_size=1000,\n    overlap=250,\n    radius=250,\n    knn=8,\n    lazy_constraints=True,\n)\n\nmatches = sliding_window_matching(\n    ref=ref_df,\n    moving=aligned_df,\n    commonCT=commonCT,\n    optim_params=optim,\n    outprefix='results/'  # Enables resumption\n)\n</code></pre>"},{"location":"tutorials/large_datasets/#option-3-metacells-sliding-windows-best-for-very-large-data","title":"Option 3: Metacells + Sliding Windows (Best for Very Large Data)","text":"<p>Best for: 50,000+ cells.</p> <pre><code>from src import greedy_triangle_collapse, sliding_window_matching\nfrom src import unpack_metacell_matches, init_optim_params\n\n# Create metacells for both datasets\nmc_aligned, _ = greedy_triangle_collapse(\n    aligned_df, max_metacell_size=3, r_max=500\n)\nmc_ref, _ = greedy_triangle_collapse(\n    ref_df, max_metacell_size=3, r_max=500\n)\n\nprint(f\"Aligned: {len(aligned_df)} -&gt; {len(mc_aligned)}\")\nprint(f\"Ref: {len(ref_df)} -&gt; {len(mc_ref)}\")\n\n# Run sliding windows on metacells\noptim = init_optim_params(\n    window_size=1000,\n    overlap=250,\n    cell_id_col='Cell_Num',\n)\n\nmetacell_matches = sliding_window_matching(\n    ref=mc_ref,\n    moving=mc_aligned,\n    commonCT=commonCT,\n    optim_params=optim,\n    outprefix='results/'\n)\n\n# Unpack to individual cells\nindividual_matches = unpack_metacell_matches(\n    metacell_matches, mc_aligned, mc_ref,\n    aligned_df=aligned_df, ref_df=ref_df,\n    strategy='nearest'\n)\n</code></pre>"},{"location":"tutorials/large_datasets/#memory-management","title":"Memory Management","text":""},{"location":"tutorials/large_datasets/#monitor-memory-usage","title":"Monitor Memory Usage","text":"<pre><code>import psutil\n\ndef print_memory():\n    process = psutil.Process()\n    mem = process.memory_info().rss / 1024 / 1024 / 1024\n    print(f\"Memory: {mem:.2f} GB\")\n\nprint_memory()  # Check before\nmatches = run_same(...)\nprint_memory()  # Check after\n</code></pre>"},{"location":"tutorials/large_datasets/#reduce-memory-with-lazy-constraints","title":"Reduce Memory with Lazy Constraints","text":"<pre><code># Lazy mode: O(n) memory instead of O(n*k^3)\noptim = init_optim_params(lazy_constraints=True)\n</code></pre>"},{"location":"tutorials/large_datasets/#reduce-knn","title":"Reduce KNN","text":"<pre><code># Fewer neighbors = fewer constraints\noptim = init_optim_params(knn=5)  # Default is 8\n</code></pre>"},{"location":"tutorials/large_datasets/#speed-optimization","title":"Speed Optimization","text":""},{"location":"tutorials/large_datasets/#use-warm-start","title":"Use Warm Start","text":"<pre><code>gurobi = init_gurobi_params(init_method='greedy')\n</code></pre>"},{"location":"tutorials/large_datasets/#allow-earlier-termination","title":"Allow Earlier Termination","text":"<pre><code>gurobi = init_gurobi_params(\n    mip_gap=0.10,      # Accept 10% gap\n    time_limit=1800,   # 30 min per window\n)\n</code></pre>"},{"location":"tutorials/large_datasets/#reduce-triangle-constraints","title":"Reduce Triangle Constraints","text":"<pre><code>optim = init_optim_params(\n    ignore_same_type_triangles=True,  # Skip homogeneous triangles\n    min_angle_deg=20,                  # Filter more thin triangles\n)\n</code></pre>"},{"location":"tutorials/large_datasets/#resumption","title":"Resumption","text":"<p>Sliding window matching supports resumption:</p> <pre><code># First run (interrupted)\nmatches = sliding_window_matching(..., outprefix='results/')\n# ^C (interrupted at window 5/10)\n\n# Resume (automatically continues from window 6)\nmatches = sliding_window_matching(..., outprefix='results/')\n# Continues from saved progress\n</code></pre>"},{"location":"tutorials/large_datasets/#parallel-processing","title":"Parallel Processing","text":"<p>For very large datasets, run windows in parallel:</p> <pre><code># Manual parallelization (advanced)\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef process_window(window_bounds):\n    x_min, x_max, y_min, y_max = window_bounds\n    ref_subset = ref_df[\n        (ref_df['X'] &gt;= x_min) &amp; (ref_df['X'] &lt; x_max) &amp;\n        (ref_df['Y'] &gt;= y_min) &amp; (ref_df['Y'] &lt; y_max)\n    ]\n    aligned_subset = aligned_df[\n        (aligned_df['X'] &gt;= x_min) &amp; (aligned_df['X'] &lt; x_max) &amp;\n        (aligned_df['Y'] &gt;= y_min) &amp; (aligned_df['Y'] &lt; y_max)\n    ]\n    return run_same(ref_subset, aligned_subset, commonCT)\n\n# Create window list\nwindows = [(x, x+1000, y, y+1000)\n           for x in range(0, 5000, 750)\n           for y in range(0, 5000, 750)]\n\n# Process in parallel\nwith ProcessPoolExecutor(max_workers=4) as executor:\n    results = list(executor.map(process_window, windows))\n</code></pre>"},{"location":"tutorials/large_datasets/#benchmarking-results","title":"Benchmarking Results","text":"Cells Metacells Windows Time Memory 5,000 None None 5 min 2 GB 10,000 1,000 None 8 min 3 GB 50,000 5,000 10\u00d710 30 min 8 GB 100,000 10,000 10\u00d710 60 min 12 GB <p>Results on 32-core server with 128 GB RAM</p>"},{"location":"tutorials/synthetic/","title":"Synthetic Benchmarks Tutorial","text":"<p>This tutorial shows how to use SAME's synthetic data generation for benchmarking and validation.</p>"},{"location":"tutorials/synthetic/#overview","title":"Overview","text":"<p>The synthetic benchmark creates a 4-quadrant grid with different challenges:</p> <ul> <li>Top-Left: Missing class (some cells removed in query)</li> <li>Top-Right: Noisy labels (uncertain cell type probabilities)</li> <li>Bottom-Right: Space tearing (point swaps + shear)</li> <li>Bottom-Left: Topological split (one region splits into two)</li> </ul>"},{"location":"tutorials/synthetic/#generate-benchmark-data","title":"Generate Benchmark Data","text":"<pre><code>from src.synthetic_datagen import (\n    create_full_benchmark,\n    visualize_benchmark,\n    print_statistics,\n    CLASS_NAMES,\n    CLASS_COLORS\n)\nimport numpy as np\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Create benchmark\nref_df, query_df, quadrants, ground_truth_df, extra_df = create_full_benchmark()\n\n# Print statistics\nprint_statistics(ref_df, query_df, quadrants)\nprint(f\"\\nGround truth pairs: {len(ground_truth_df)}\")\n</code></pre>"},{"location":"tutorials/synthetic/#visualize-benchmark","title":"Visualize Benchmark","text":"<pre><code>import matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 7))\n\n# Reference\nax = axes[0]\nfor ct in CLASS_NAMES:\n    subset = ref_df[ref_df['cell_type'] == ct]\n    ax.scatter(subset['X'], subset['Y'], c=CLASS_COLORS[ct],\n               label=ct, s=20, alpha=0.7)\nax.set_title('Reference')\nax.legend()\nax.set_aspect('equal')\n\n# Query\nax = axes[1]\nfor ct in CLASS_NAMES:\n    subset = query_df[query_df['cell_type'] == ct]\n    ax.scatter(subset['X'], subset['Y'], c=CLASS_COLORS[ct],\n               label=ct, s=20, alpha=0.7)\nax.set_title('Query (to be matched)')\nax.legend()\nax.set_aspect('equal')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"tutorials/synthetic/#run-same-on-benchmark","title":"Run SAME on Benchmark","text":"<pre><code>from src import run_same, init_optim_params\n\n# Extract cell type columns\ncommonCT = CLASS_NAMES\n\n# Configure SAME\noptim = init_optim_params(\n    radius=50,            # Small radius for grid data\n    knn=5,\n    lazy_constraints=True,\n    delaunay_penalty=10,  # Penalize space-tearing\n)\n\n# Run SAME\nmatches, var_out = run_same(\n    ref_df=ref_df,\n    aligned_df=query_df,\n    commonCT=commonCT,\n    optim_params=optim,\n)\n\nprint(f\"Found {len(matches)} matches\")\n</code></pre>"},{"location":"tutorials/synthetic/#evaluate-against-ground-truth","title":"Evaluate Against Ground Truth","text":"<pre><code>def evaluate_matches(matches, ground_truth, query_df, ref_df):\n    \"\"\"Compute matching accuracy metrics.\"\"\"\n\n    # Create lookup for ground truth\n    gt_map = {}\n    for _, row in ground_truth.iterrows():\n        gt_map[row['query_idx']] = row['ref_idx']\n\n    # Evaluate\n    correct = 0\n    total = 0\n\n    for _, row in matches.iterrows():\n        query_idx = row['aligned_idx']\n        pred_ref = row['ref_idx']\n\n        if query_idx in gt_map:\n            total += 1\n            if gt_map[query_idx] == pred_ref:\n                correct += 1\n\n    # Metrics\n    accuracy = correct / total if total &gt; 0 else 0\n    recall = correct / len(ground_truth) if len(ground_truth) &gt; 0 else 0\n    precision = correct / len(matches) if len(matches) &gt; 0 else 0\n\n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': 2 * precision * recall / (precision + recall) if (precision + recall) &gt; 0 else 0,\n        'correct': correct,\n        'total_gt': len(ground_truth),\n        'total_pred': len(matches),\n    }\n\nmetrics = evaluate_matches(matches, ground_truth_df, query_df, ref_df)\n\nprint(\"\\nMatching Metrics:\")\nprint(f\"  Accuracy: {metrics['accuracy']:.1%}\")\nprint(f\"  Precision: {metrics['precision']:.1%}\")\nprint(f\"  Recall: {metrics['recall']:.1%}\")\nprint(f\"  F1 Score: {metrics['f1']:.3f}\")\n</code></pre>"},{"location":"tutorials/synthetic/#per-quadrant-analysis","title":"Per-Quadrant Analysis","text":"<pre><code>def evaluate_quadrant(matches, ground_truth, quadrant_bounds):\n    \"\"\"Evaluate matches within a specific quadrant.\"\"\"\n    x_min, x_max, y_min, y_max = quadrant_bounds\n\n    # Filter to quadrant\n    quad_matches = matches[\n        (matches['X'] &gt;= x_min) &amp; (matches['X'] &lt; x_max) &amp;\n        (matches['Y'] &gt;= y_min) &amp; (matches['Y'] &lt; y_max)\n    ]\n\n    quad_gt = ground_truth[\n        (ground_truth['X'] &gt;= x_min) &amp; (ground_truth['X'] &lt; x_max) &amp;\n        (ground_truth['Y'] &gt;= y_min) &amp; (ground_truth['Y'] &lt; y_max)\n    ]\n\n    return evaluate_matches(quad_matches, quad_gt, None, None)\n\n# Define quadrant bounds\nquadrant_names = {\n    'Top-Left (Missing Class)': (-110, 0, 0, 110),\n    'Top-Right (Noisy Labels)': (0, 110, 0, 110),\n    'Bottom-Right (Space Tearing)': (0, 110, -110, 0),\n    'Bottom-Left (Topological Split)': (-110, 0, -110, 0),\n}\n\nprint(\"\\nPer-Quadrant Results:\")\nfor name, bounds in quadrant_names.items():\n    metrics = evaluate_quadrant(matches, ground_truth_df, bounds)\n    print(f\"\\n{name}:\")\n    print(f\"  Accuracy: {metrics['accuracy']:.1%}\")\n    print(f\"  F1: {metrics['f1']:.3f}\")\n</code></pre>"},{"location":"tutorials/synthetic/#visualize-space-tearing-detection","title":"Visualize Space-Tearing Detection","text":"<pre><code># Highlight matches with triangle violations\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Good matches\ngood_matches = matches[~matches['triangle_violation']]\nax.scatter(good_matches['X'], good_matches['Y'],\n           c='green', s=30, alpha=0.5, label='Valid matches')\n\n# Violated matches (space-tearing)\nviolated_matches = matches[matches['triangle_violation']]\nax.scatter(violated_matches['X'], violated_matches['Y'],\n           c='red', s=50, marker='x', label='Space-tearing')\n\nax.set_title(f'Space-Tearing Detection ({len(violated_matches)} violations)')\nax.legend()\nax.set_aspect('equal')\nplt.show()\n</code></pre>"},{"location":"tutorials/synthetic/#compare-different-parameters","title":"Compare Different Parameters","text":"<pre><code>def run_with_params(ref_df, query_df, commonCT, delaunay_penalty):\n    \"\"\"Run SAME with specific delaunay_penalty.\"\"\"\n    optim = init_optim_params(\n        radius=50,\n        knn=5,\n        delaunay_penalty=delaunay_penalty,\n        lazy_constraints=True,\n    )\n    matches, _ = run_same(ref_df, query_df, commonCT, optim_params=optim)\n    return evaluate_matches(matches, ground_truth_df, query_df, ref_df)\n\n# Compare different penalty values\npenalties = [1, 5, 10, 50, 100]\nresults = []\n\nfor p in penalties:\n    metrics = run_with_params(ref_df, query_df, commonCT, p)\n    results.append({\n        'penalty': p,\n        'accuracy': metrics['accuracy'],\n        'f1': metrics['f1'],\n        'recall': metrics['recall'],\n    })\n\n# Plot results\nimport pandas as pd\nresults_df = pd.DataFrame(results)\n\nfig, ax = plt.subplots(figsize=(8, 5))\nax.plot(results_df['penalty'], results_df['accuracy'], 'o-', label='Accuracy')\nax.plot(results_df['penalty'], results_df['f1'], 's-', label='F1')\nax.plot(results_df['penalty'], results_df['recall'], '^-', label='Recall')\nax.set_xlabel('Delaunay Penalty')\nax.set_ylabel('Score')\nax.set_title('Effect of Delaunay Penalty on Matching Quality')\nax.legend()\nax.set_xscale('log')\nplt.show()\n</code></pre>"},{"location":"tutorials/synthetic/#create-custom-benchmarks","title":"Create Custom Benchmarks","text":"<pre><code>from src.synthetic_datagen import (\n    create_diffeomorphic_grid,\n    create_space_tearing_grid,\n    create_topological_split,\n)\n\n# Create a custom grid with space tearing\nref_grid, query_grid, gt = create_space_tearing_grid(\n    n_x=20,           # 20x20 grid\n    n_y=20,\n    spacing=10,\n    n_classes=3,\n    n_swaps=5,        # Number of point swaps\n    shear_amount=0.2, # Shear deformation\n)\n\nprint(f\"Custom grid: {len(ref_grid)} ref, {len(query_grid)} query cells\")\n</code></pre>"}]}